{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/maple-buice/chart-hero/blob/main/colab/transformer_training_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUQ1odMpqK1f"
   },
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJsmeNtbqK1g"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kwo6JqcWqK1g"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "import os\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set up project directory\n",
    "\n",
    "PROJECT_DIR = '/content/drive/MyDrive/chart-hero'\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "%cd {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0jRvg4sqK1g"
   },
   "outputs": [],
   "source": [
    "# Clone or update repository\n",
    "import os\n",
    "\n",
    "if not os.path.exists('.git'):\n",
    "    !git clone https://github.com/maple-buice/chart-hero.git .\n",
    "else:\n",
    "    !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtD-YME7qK1h"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibgreACNqK1h"
   },
   "source": [
    "## 2. Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80Z9V6ccqK1h"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "DATASET_DIR = os.path.join(PROJECT_DIR, 'datasets')\n",
    "\n",
    "# Dataset URL and paths\n",
    "DATASET_URL = \"https://storage.googleapis.com/magentadata/datasets/e-gmd/v1.0.0/e-gmd-v1.0.0.zip\"\n",
    "ZIP_FILE_NAME = os.path.basename(DATASET_URL)\n",
    "DRIVE_ZIP_PATH = os.path.join(DATASET_DIR, ZIP_FILE_NAME)\n",
    "\n",
    "EXPECTED_UNZIPPED_CONTENT_NAME = \"e-gmd-v1.0.0\"\n",
    "EXPECTED_UNZIPPED_CONTENT_PATH = os.path.join(DATASET_DIR, EXPECTED_UNZIPPED_CONTENT_NAME)\n",
    "\n",
    "SENTINEL_FILE_NAME = \".unzip_successful_sentinel\"\n",
    "SENTINEL_FILE_PATH = os.path.join(DATASET_DIR, SENTINEL_FILE_NAME)\n",
    "\n",
    "# --- Setup ---\n",
    "print(\"Starting dataset setup...\")\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(SENTINEL_FILE_PATH):\n",
    "    if not os.path.exists(DRIVE_ZIP_PATH):\n",
    "        print(f\"ZIP file not found at {DRIVE_ZIP_PATH}. Downloading...\")\n",
    "        !wget -O '{DRIVE_ZIP_PATH}' '{DATASET_URL}'\n",
    "    else:\n",
    "        print(f\"ZIP file already exists at {DRIVE_ZIP_PATH}. Skipping download.\")\n",
    "\n",
    "    print(f\"Unzipping '{DRIVE_ZIP_PATH}' to '{DATASET_DIR}'...\")\n",
    "    !unzip -nq '{DRIVE_ZIP_PATH}' -d '{DATASET_DIR}'\n",
    "\n",
    "    if os.path.exists(EXPECTED_UNZIPPED_CONTENT_PATH):\n",
    "        print(\"Unzip successful.\")\n",
    "        with open(SENTINEL_FILE_PATH, 'w') as f:\n",
    "            f.write('unzip complete')\n",
    "    else:\n",
    "        print(\"Unzip failed.\")\n",
    "else:\n",
    "    print(\"Dataset already unzipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBCDd7MDqK1h"
   },
   "outputs": [],
   "source": [
    "# Prepare training data (if not already processed)\n",
    "PROCESSED_DIR = os.path.join(DATASET_DIR, 'processed')\n",
    "if not os.path.exists(PROCESSED_DIR):\n",
    "    print(\"Processing raw EGMD data...\")\n",
    "    !python src/chart_hero/prepare_egmd_data.py --output-dir {PROCESSED_DIR}\n",
    "else:\n",
    "    print(\"Processed data already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4GOGPreqK1h"
   },
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tSmGXtnAqK1h"
   },
   "outputs": [],
   "source": [
    "# Set up W&B logging\n",
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fe08HFvqK1h"
   },
   "outputs": [],
   "source": [
    "# Test transformer setup\n",
    "!python tests/model_training/test_transformer_setup.py --config cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1SFZlBqCqK1h"
   },
   "outputs": [],
   "source": [
    "# Start training with cloud configuration\n",
    "!python src/chart_hero/model_training/train_transformer.py \\\n",
    "    --config cloud \\\n",
    "    --project-name chart-hero-transformer-colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bDkyd8nqK1h"
   },
   "source": [
    "## 4. Resume Training (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TD03wwEqK1h"
   },
   "outputs": [],
   "source": [
    "# Resume from checkpoint\n",
    "CHECKPOINT_PATH = \"/content/drive/MyDrive/chart-hero/models/local_transformer_models/last.ckpt\"\n",
    "\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    !python src/chart_hero/model_training/train_transformer.py \\\\\n",
    "        --config cloud \\\\\n",
    "        --resume {CHECKPOINT_PATH} \\\\\n",
    "        --project-name chart-hero-transformer-colab\n",
    "else:\n",
    "    print(f\"Checkpoint not found: {CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_jtaL-mqK1h"
   },
   "source": [
    "## 5. Model Evaluation and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AaRwU8F9qK1h"
   },
   "outputs": [],
   "source": [
    "# Load and evaluate best model\n",
    "import torch\n",
    "\n",
    "from chart_hero.model_training.train_transformer import DrumTranscriptionModule\n",
    "from chart_hero.model_training.transformer_config import get_config\n",
    "\n",
    "config = get_config(\"cloud\")\n",
    "best_model_path = \"/content/drive/MyDrive/chart-hero/models/local_transformer_models/best_model.ckpt\"\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    model = DrumTranscriptionModule.load_from_checkpoint(best_model_path)\n",
    "    model.eval()\n",
    "    print(\"Model loaded successfully!\")\n",
    "\n",
    "    # Export to ONNX for deployment\n",
    "    dummy_input = torch.randn(1, 1, 256, 128)\n",
    "    onnx_path = \"/content/drive/MyDrive/chart-hero/models/drum_transformer.onnx\"\n",
    "\n",
    "    torch.onnx.export(\n",
    "        model.model,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['spectrogram'],\n",
    "        output_names=['logits'],\n",
    "        dynamic_axes={\n",
    "            'spectrogram': {0: 'batch_size', 2: 'time'},\n",
    "            'logits': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"Model exported to ONNX: {onnx_path}\")\n",
    "else:\n",
    "    print(f\"Best model not found: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9bLGHPNqK1h"
   },
   "source": [
    "## 6. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSpRRAa1qK1h"
   },
   "outputs": [],
   "source": [
    "# Clean up temporary files and finish W&B run\n",
    "wandb.finish()\n",
    "\n",
    "# Show final model and log locations\n",
    "print(\"Training completed!\")\n",
    "print(\"Models saved to: /content/drive/MyDrive/chart-hero/models/\")\n",
    "print(\"Logs saved to: /content/drive/MyDrive/chart-hero/logs/\")\n",
    "print(\"Datasets saved to: /content/drive/MyDrive/chart-hero/datasets/\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
