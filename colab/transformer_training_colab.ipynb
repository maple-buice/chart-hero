{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maple-buice/chart-hero/blob/main/colab/transformer_training_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUQ1odMpqK1f"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJsmeNtbqK1g",
        "outputId": "8c2a628b-d2df-49b1-ab3b-9fdcdc9ca52e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue May 27 12:13:08 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "Memory: 15.8 GB\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwo6JqcWqK1g",
        "outputId": "4b420a13-3e3d-446f-c580-9715f3680c15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/chart-hero\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up project directory\n",
        "PROJECT_DIR = '/content/drive/MyDrive/chart-hero'\n",
        "!mkdir -p {PROJECT_DIR}\n",
        "%cd {PROJECT_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0jRvg4sqK1g",
        "outputId": "f20954a9-eae1-43d7-9313-5f69eca46554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/chart-hero/chart-hero\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 8 (delta 4), reused 4 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (8/8), 2.01 KiB | 3.00 KiB/s, done.\n",
            "From https://github.com/maple-buice/chart-hero\n",
            "   b8042ad..c5df979  main       -> origin/main\n",
            "Updating b8042ad..c5df979\n",
            "Fast-forward\n",
            " colab/transformer_training_colab.ipynb | 92 \u001b[32m++++++++++++++++++++++++++\u001b[m\u001b[31m--------\u001b[m\n",
            " 1 file changed, 71 insertions(+), 21 deletions(-)\n",
            "/content/drive/MyDrive/chart-hero\n",
            "/content/drive/MyDrive/chart-hero/chart-hero\n"
          ]
        }
      ],
      "source": [
        "# Clone or update repository\n",
        "import os\n",
        "if not os.path.exists('chart-hero'):\n",
        "    !git clone https://github.com/maple-buice/chart-hero.git\n",
        "else:\n",
        "    %cd chart-hero\n",
        "    !git pull\n",
        "    %cd ..\n",
        "\n",
        "%cd chart-hero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtD-YME7qK1h",
        "outputId": "7cbe9c04-0db0-4394-c5dc-9ee6f2278760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m115.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q pytorch-lightning transformers timm wandb\n",
        "!pip install -q librosa soundfile scikit-learn pandas numpy matplotlib seaborn tqdm\n",
        "!pip install -q ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibgreACNqK1h"
      },
      "source": [
        "## 2. Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80Z9V6ccqK1h",
        "outputId": "c984337f-9e4a-46da-e89b-1cb3fd20c02a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Download Step ---\n",
            "Downloading https://storage.googleapis.com/magentadata/datasets/e-gmd/v1.0.0/e-gmd-v1.0.0.zip to instance storage (/content/e-gmd-v1.0.0.zip)...\n",
            "--2025-05-27 16:22:04--  https://storage.googleapis.com/magentadata/datasets/e-gmd/v1.0.0/e-gmd-v1.0.0.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.170.207, 142.251.175.207, 74.125.24.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.170.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 96422999145 (90G) [application/zip]\n",
            "Saving to: ‘/content/e-gmd-v1.0.0.zip’\n",
            "\n",
            "zip                   0%[                    ] 343.84M  18.4MB/s    eta 84m 31s^C\n",
            "Download complete.\n",
            "\n",
            "--- 2. Unzip Step ---\n",
            "Unzipping /content/e-gmd-v1.0.0.zip to /content/drive/MyDrive/chart-hero/datasets...\n",
            "[/content/e-gmd-v1.0.0.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/e-gmd-v1.0.0.zip or\n",
            "        /content/e-gmd-v1.0.0.zip.zip, and cannot find /content/e-gmd-v1.0.0.zip.ZIP, period.\n",
            "Unzipping may have failed. Expected content not found at /content/drive/MyDrive/chart-hero/datasets/e-gmd-v1.0.0.\n",
            "Temporary ZIP file /content/e-gmd-v1.0.0.zip will be kept for inspection.\n",
            "\n",
            "Final check - Dataset directory contents (/content/drive/MyDrive/chart-hero/datasets):\n",
            "total 94163086\n",
            "-rw------- 1 root root 96422999145 Mar 10  2020 e-gmd-v1.0.0.zip\n",
            "\n",
            "Final check - Instance /content directory contents:\n",
            "total 352520\n",
            "drwxr-xr-x 1 root root      4096 May 27 16:22 .\n",
            "drwxr-xr-x 1 root root      4096 May 27 12:38 ..\n",
            "drwxr-xr-x 4 root root      4096 May 14 13:38 .config\n",
            "drwx------ 7 root root      4096 May 27 12:46 drive\n",
            "-rw-r--r-- 1 root root 360955904 May 27 16:22 e-gmd-v1.0.0.zip\n",
            "drwxr-xr-x 1 root root      4096 May 14 13:38 sample_data\n"
          ]
        }
      ],
      "source": [
        "# Download and extract Expanded Groove MIDI Dataset\n",
        "# Separated download and unzip steps with individual checks.\n",
        "\n",
        "import os # Ensure os is imported\n",
        "\n",
        "DATASET_URL = \"https://storage.googleapis.com/magentadata/datasets/e-gmd/v1.0.0/e-gmd-v1.0.0.zip\"\n",
        "# Target directory on Google Drive for the unzipped dataset\n",
        "DATASET_DIR = \"/content/drive/MyDrive/chart-hero/datasets\"\n",
        "# Path to a representative file/directory within the unzipped dataset to check for existence\n",
        "# Adjust if the structure of your unzipped dataset is different. This assumes a directory named 'e-gmd-v1.0.0' is created.\n",
        "EXPECTED_DATASET_CONTENT_PATH = os.path.join(DATASET_DIR, \"e-gmd-v1.0.0\")\n",
        "\n",
        "# Temporary path on Colab instance storage for the downloaded ZIP file\n",
        "INSTANCE_TEMP_ZIP_FILENAME = \"e-gmd-v1.0.0.zip\"\n",
        "INSTANCE_TEMP_ZIP_PATH = os.path.join(DATASET_DIR, INSTANCE_TEMP_ZIP_FILENAME)\n",
        "\n",
        "print(\"--- 1. Download Step ---\")\n",
        "# Check if data is already unzipped (no need to download then)\n",
        "if os.path.exists(EXPECTED_DATASET_CONTENT_PATH):\n",
        "    print(f\"Dataset already unzipped at {EXPECTED_DATASET_CONTENT_PATH}. Skipping download.\")\n",
        "# Check if ZIP is already downloaded to instance\n",
        "elif os.path.exists(INSTANCE_TEMP_ZIP_PATH):\n",
        "    print(f\"ZIP file already downloaded to instance storage at {INSTANCE_TEMP_ZIP_PATH}. Skipping download.\")\n",
        "# Otherwise, download\n",
        "else:\n",
        "    print(f\"Downloading {DATASET_URL} to instance storage ({INSTANCE_TEMP_ZIP_PATH})...\")\n",
        "    # Ensure /content directory exists for wget, though it usually does by default\n",
        "    !mkdir -p /content\n",
        "    !wget -O {INSTANCE_TEMP_ZIP_PATH} {DATASET_URL}\n",
        "    if os.path.exists(INSTANCE_TEMP_ZIP_PATH):\n",
        "        print(\"Download complete.\")\n",
        "    else:\n",
        "        print(f\"Download failed. ZIP file not found at {INSTANCE_TEMP_ZIP_PATH}.\")\n",
        "\n",
        "print(\"\\n--- 2. Unzip Step ---\")\n",
        "# Check if data is already unzipped\n",
        "if os.path.exists(EXPECTED_DATASET_CONTENT_PATH):\n",
        "    print(f\"Dataset already unzipped at {EXPECTED_DATASET_CONTENT_PATH}. Skipping unzip.\")\n",
        "else:\n",
        "    # Check if the ZIP file exists on the instance (either freshly downloaded or from a previous run)\n",
        "    if os.path.exists(INSTANCE_TEMP_ZIP_PATH):\n",
        "        print(f\"Unzipping {INSTANCE_TEMP_ZIP_PATH} to {DATASET_DIR}...\")\n",
        "        # Ensure target directory on Google Drive exists\n",
        "        !mkdir -p {DATASET_DIR}\n",
        "        # The -o option overwrites files without prompting. -q for quiet. -d for destination.\n",
        "        !unzip -oq {INSTANCE_TEMP_ZIP_PATH} -d {DATASET_DIR}\n",
        "\n",
        "        # Verify unzipping by checking for the expected content path\n",
        "        if os.path.exists(EXPECTED_DATASET_CONTENT_PATH):\n",
        "            print(\"Unzipping complete.\")\n",
        "        else:\n",
        "            print(f\"Unzipping may have failed. Expected content not found at {EXPECTED_DATASET_CONTENT_PATH}.\")\n",
        "            print(f\"Temporary ZIP file {INSTANCE_TEMP_ZIP_PATH} will be kept for inspection.\")\n",
        "    else:\n",
        "        # This case means the data isn't unzipped, and the ZIP isn't on the instance.\n",
        "        print(f\"ZIP file not found at {INSTANCE_TEMP_ZIP_PATH}. Cannot unzip. Please ensure download step was successful or the file exists.\")\n",
        "\n",
        "print(f\"\\nFinal check - Dataset directory contents ({DATASET_DIR}):\")\n",
        "!ls -la {DATASET_DIR}\n",
        "print(f\"\\nFinal check - Instance /content directory contents:\")\n",
        "!ls -la /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBCDd7MDqK1h"
      },
      "outputs": [],
      "source": [
        "# Prepare training data (if not already processed)\n",
        "# This cell converts the raw EGMD data to transformer-compatible format\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/chart-hero')\n",
        "\n",
        "from model_training.data_preparation import data_preparation\n",
        "from model_training.transformer_data import convert_legacy_data\n",
        "\n",
        "# Process raw EGMD data\n",
        "egmd_dir = \"/content/drive/MyDrive/chart-hero/datasets/expanded-groove-midi\"\n",
        "processed_dir = \"/content/drive/MyDrive/chart-hero/datasets/processed\"\n",
        "\n",
        "if not os.path.exists(processed_dir):\n",
        "    print(\"Processing raw EGMD data...\")\n",
        "\n",
        "    # Create data preparation instance\n",
        "    data_prep = data_preparation(\n",
        "        directory_path=egmd_dir,\n",
        "        dataset='egmd',\n",
        "        sample_ratio=1.0,\n",
        "        diff_threshold=1.0\n",
        "    )\n",
        "\n",
        "    # Create audio set with batching\n",
        "    data_prep.create_audio_set(\n",
        "        pad_before=0.1,\n",
        "        pad_after=0.1,\n",
        "        fix_length=10.0,  # 10 second segments\n",
        "        batching=True,\n",
        "        dir_path=processed_dir,\n",
        "        num_batches=20\n",
        "    )\n",
        "\n",
        "    print(\"Data processing completed!\")\n",
        "else:\n",
        "    print(\"Processed data already exists.\")\n",
        "\n",
        "!ls -la {processed_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4GOGPreqK1h"
      },
      "source": [
        "## 3. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSmGXtnAqK1h"
      },
      "outputs": [],
      "source": [
        "# Set up W&B logging\n",
        "import wandb\n",
        "\n",
        "# Login to W&B (you'll need to provide your API key)\n",
        "wandb.login()\n",
        "\n",
        "# Or set the API key directly\n",
        "# wandb.login(key=\"your-wandb-api-key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fe08HFvqK1h"
      },
      "outputs": [],
      "source": [
        "# Test transformer setup\n",
        "!python model_training/test_transformer_setup.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SFZlBqCqK1h"
      },
      "outputs": [],
      "source": [
        "# Start training with cloud configuration\n",
        "DATA_DIR = \"/content/drive/MyDrive/chart-hero/datasets/processed\"\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/chart-hero/datasets/expanded-groove-midi\"\n",
        "\n",
        "!python model_training/train_transformer.py \\\n",
        "    --config cloud \\\n",
        "    --data-dir {DATA_DIR} \\\n",
        "    --audio-dir {AUDIO_DIR} \\\n",
        "    --project-name chart-hero-transformer-colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bDkyd8nqK1h"
      },
      "source": [
        "## 4. Resume Training (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TD03wwEqK1h"
      },
      "outputs": [],
      "source": [
        "# Resume from checkpoint\n",
        "CHECKPOINT_PATH = \"/content/drive/MyDrive/chart-hero/models/last.ckpt\"\n",
        "\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "    !python model_training/train_transformer.py \\\n",
        "        --config cloud \\\n",
        "        --data-dir {DATA_DIR} \\\n",
        "        --audio-dir {AUDIO_DIR} \\\n",
        "        --resume {CHECKPOINT_PATH} \\\n",
        "        --project-name chart-hero-transformer-colab\n",
        "else:\n",
        "    print(f\"Checkpoint not found: {CHECKPOINT_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_jtaL-mqK1h"
      },
      "source": [
        "## 5. Model Evaluation and Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaRwU8F9qK1h"
      },
      "outputs": [],
      "source": [
        "# Load and evaluate best model\n",
        "import torch\n",
        "from model_training.train_transformer import DrumTranscriptionModule\n",
        "from model_training.transformer_config import get_config\n",
        "\n",
        "config = get_config(\"cloud\")\n",
        "best_model_path = \"/content/drive/MyDrive/chart-hero/models/best_model.ckpt\"\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    model = DrumTranscriptionModule.load_from_checkpoint(best_model_path)\n",
        "    model.eval()\n",
        "    print(\"Model loaded successfully!\")\n",
        "\n",
        "    # Export to ONNX for deployment\n",
        "    dummy_input = torch.randn(1, 1, 256, 128)\n",
        "    onnx_path = \"/content/drive/MyDrive/chart-hero/models/drum_transformer.onnx\"\n",
        "\n",
        "    torch.onnx.export(\n",
        "        model.model,\n",
        "        dummy_input,\n",
        "        onnx_path,\n",
        "        export_params=True,\n",
        "        opset_version=11,\n",
        "        do_constant_folding=True,\n",
        "        input_names=['spectrogram'],\n",
        "        output_names=['logits'],\n",
        "        dynamic_axes={\n",
        "            'spectrogram': {0: 'batch_size', 2: 'time'},\n",
        "            'logits': {0: 'batch_size'}\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(f\"Model exported to ONNX: {onnx_path}\")\n",
        "else:\n",
        "    print(f\"Best model not found: {best_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9bLGHPNqK1h"
      },
      "source": [
        "## 6. Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSpRRAa1qK1h"
      },
      "outputs": [],
      "source": [
        "# Clean up temporary files and finish W&B run\n",
        "wandb.finish()\n",
        "\n",
        "# Show final model and log locations\n",
        "print(\"Training completed!\")\n",
        "print(f\"Models saved to: /content/drive/MyDrive/chart-hero/models/\")\n",
        "print(f\"Logs saved to: /content/drive/MyDrive/chart-hero/logs/\")\n",
        "print(f\"Datasets saved to: /content/drive/MyDrive/chart-hero/datasets/\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}