{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maple-buice/chart-hero/blob/main/colab/transformer_training_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUQ1odMpqK1f"
      },
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YJsmeNtbqK1g",
        "outputId": "8c2a628b-d2df-49b1-ab3b-9fdcdc9ca52e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 27 12:13:08 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "Memory: 15.8 GB\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Kwo6JqcWqK1g",
        "outputId": "252c47f0-a68d-4754-8f02-90da2c45a079",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/chart-hero\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up project directory\n",
        "PROJECT_DIR = '/content/drive/MyDrive/chart-hero'\n",
        "!mkdir -p {PROJECT_DIR}\n",
        "%cd {PROJECT_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "X0jRvg4sqK1g",
        "outputId": "0ee9d0a0-4c80-4d08-dc72-8f7c258ce622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'chart-hero'...\n",
            "remote: Enumerating objects: 341, done.\u001b[K\n",
            "remote: Counting objects: 100% (341/341), done.\u001b[K\n",
            "remote: Compressing objects: 100% (224/224), done.\u001b[K\n",
            "remote: Total 341 (delta 177), reused 262 (delta 101), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (341/341), 4.31 MiB | 18.52 MiB/s, done.\n",
            "Resolving deltas: 100% (177/177), done.\n",
            "/content/drive/MyDrive/chart-hero/chart-hero\n"
          ]
        }
      ],
      "source": [
        "# Clone or update repository\n",
        "import os\n",
        "if not os.path.exists('chart-hero'):\n",
        "    !git clone https://github.com/maple-buice/chart-hero.git\n",
        "else:\n",
        "    %cd chart-hero\n",
        "    !git pull\n",
        "    %cd ..\n",
        "\n",
        "%cd chart-hero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtD-YME7qK1h",
        "outputId": "7cbe9c04-0db0-4394-c5dc-9ee6f2278760",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m115.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q pytorch-lightning transformers timm wandb\n",
        "!pip install -q librosa soundfile scikit-learn pandas numpy matplotlib seaborn tqdm\n",
        "!pip install -q ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibgreACNqK1h"
      },
      "source": [
        "## 2. Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80Z9V6ccqK1h"
      },
      "outputs": [],
      "source": [
        "# Download and extract Expanded Groove MIDI Dataset\n",
        "# Note: Replace with actual download commands for your dataset\n",
        "\n",
        "DATASET_URL = \"https://storage.googleapis.com/magentadata/datasets/e-gmd/v1.0.0/e-gmd-v1.0.0.zip\"\n",
        "DATASET_DIR = \"/content/drive/MyDrive/chart-hero/datasets\"\n",
        "\n",
        "!mkdir -p {DATASET_DIR}\n",
        "\n",
        "# Download dataset (uncomment and modify as needed)\n",
        "# !wget -O {DATASET_DIR}/dataset.zip {DATASET_URL}\n",
        "# !unzip -q {DATASET_DIR}/dataset.zip -d {DATASET_DIR}\n",
        "\n",
        "print(f\"Dataset directory: {DATASET_DIR}\")\n",
        "!ls -la {DATASET_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBCDd7MDqK1h"
      },
      "outputs": [],
      "source": [
        "# Prepare training data (if not already processed)\n",
        "# This cell converts the raw EGMD data to transformer-compatible format\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/chart-hero')\n",
        "\n",
        "from model_training.data_preparation import data_preparation\n",
        "from model_training.transformer_data import convert_legacy_data\n",
        "\n",
        "# Process raw EGMD data\n",
        "egmd_dir = \"/content/drive/MyDrive/chart-hero/datasets/expanded-groove-midi\"\n",
        "processed_dir = \"/content/drive/MyDrive/chart-hero/datasets/processed\"\n",
        "\n",
        "if not os.path.exists(processed_dir):\n",
        "    print(\"Processing raw EGMD data...\")\n",
        "\n",
        "    # Create data preparation instance\n",
        "    data_prep = data_preparation(\n",
        "        directory_path=egmd_dir,\n",
        "        dataset='egmd',\n",
        "        sample_ratio=1.0,\n",
        "        diff_threshold=1.0\n",
        "    )\n",
        "\n",
        "    # Create audio set with batching\n",
        "    data_prep.create_audio_set(\n",
        "        pad_before=0.1,\n",
        "        pad_after=0.1,\n",
        "        fix_length=10.0,  # 10 second segments\n",
        "        batching=True,\n",
        "        dir_path=processed_dir,\n",
        "        num_batches=20\n",
        "    )\n",
        "\n",
        "    print(\"Data processing completed!\")\n",
        "else:\n",
        "    print(\"Processed data already exists.\")\n",
        "\n",
        "!ls -la {processed_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4GOGPreqK1h"
      },
      "source": [
        "## 3. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSmGXtnAqK1h"
      },
      "outputs": [],
      "source": [
        "# Set up W&B logging\n",
        "import wandb\n",
        "\n",
        "# Login to W&B (you'll need to provide your API key)\n",
        "wandb.login()\n",
        "\n",
        "# Or set the API key directly\n",
        "# wandb.login(key=\"your-wandb-api-key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fe08HFvqK1h"
      },
      "outputs": [],
      "source": [
        "# Test transformer setup\n",
        "!python model_training/test_transformer_setup.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SFZlBqCqK1h"
      },
      "outputs": [],
      "source": [
        "# Start training with cloud configuration\n",
        "DATA_DIR = \"/content/drive/MyDrive/chart-hero/datasets/processed\"\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/chart-hero/datasets/expanded-groove-midi\"\n",
        "\n",
        "!python model_training/train_transformer.py \\\n",
        "    --config cloud \\\n",
        "    --data-dir {DATA_DIR} \\\n",
        "    --audio-dir {AUDIO_DIR} \\\n",
        "    --project-name chart-hero-transformer-colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bDkyd8nqK1h"
      },
      "source": [
        "## 4. Resume Training (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TD03wwEqK1h"
      },
      "outputs": [],
      "source": [
        "# Resume from checkpoint\n",
        "CHECKPOINT_PATH = \"/content/drive/MyDrive/chart-hero/models/last.ckpt\"\n",
        "\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "    !python model_training/train_transformer.py \\\n",
        "        --config cloud \\\n",
        "        --data-dir {DATA_DIR} \\\n",
        "        --audio-dir {AUDIO_DIR} \\\n",
        "        --resume {CHECKPOINT_PATH} \\\n",
        "        --project-name chart-hero-transformer-colab\n",
        "else:\n",
        "    print(f\"Checkpoint not found: {CHECKPOINT_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_jtaL-mqK1h"
      },
      "source": [
        "## 5. Model Evaluation and Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaRwU8F9qK1h"
      },
      "outputs": [],
      "source": [
        "# Load and evaluate best model\n",
        "import torch\n",
        "from model_training.train_transformer import DrumTranscriptionModule\n",
        "from model_training.transformer_config import get_config\n",
        "\n",
        "config = get_config(\"cloud\")\n",
        "best_model_path = \"/content/drive/MyDrive/chart-hero/models/best_model.ckpt\"\n",
        "\n",
        "if os.path.exists(best_model_path):\n",
        "    model = DrumTranscriptionModule.load_from_checkpoint(best_model_path)\n",
        "    model.eval()\n",
        "    print(\"Model loaded successfully!\")\n",
        "\n",
        "    # Export to ONNX for deployment\n",
        "    dummy_input = torch.randn(1, 1, 256, 128)\n",
        "    onnx_path = \"/content/drive/MyDrive/chart-hero/models/drum_transformer.onnx\"\n",
        "\n",
        "    torch.onnx.export(\n",
        "        model.model,\n",
        "        dummy_input,\n",
        "        onnx_path,\n",
        "        export_params=True,\n",
        "        opset_version=11,\n",
        "        do_constant_folding=True,\n",
        "        input_names=['spectrogram'],\n",
        "        output_names=['logits'],\n",
        "        dynamic_axes={\n",
        "            'spectrogram': {0: 'batch_size', 2: 'time'},\n",
        "            'logits': {0: 'batch_size'}\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(f\"Model exported to ONNX: {onnx_path}\")\n",
        "else:\n",
        "    print(f\"Best model not found: {best_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9bLGHPNqK1h"
      },
      "source": [
        "## 6. Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSpRRAa1qK1h"
      },
      "outputs": [],
      "source": [
        "# Clean up temporary files and finish W&B run\n",
        "wandb.finish()\n",
        "\n",
        "# Show final model and log locations\n",
        "print(\"Training completed!\")\n",
        "print(f\"Models saved to: /content/drive/MyDrive/chart-hero/models/\")\n",
        "print(f\"Logs saved to: /content/drive/MyDrive/chart-hero/logs/\")\n",
        "print(f\"Datasets saved to: /content/drive/MyDrive/chart-hero/datasets/\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}