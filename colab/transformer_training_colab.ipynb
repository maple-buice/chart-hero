{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/maple-buice/chart-hero/blob/main/colab/transformer_training_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55d4acd",
   "metadata": {
    "id": "e55d4acd"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/maple-buice/chart-hero/blob/main/colab/transformer_training_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02d463",
   "metadata": {
    "id": "ae02d463"
   },
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dca1e29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dca1e29",
    "outputId": "2e25c391-b084-44c1-faa5-7ba9b553fbe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Check available accelerator (GPU or TPU)\n",
    "import os, torch\n",
    "\n",
    "if \"COLAB_TPU_ADDR\" in os.environ:\n",
    "    print(\"TPU detected\")\n",
    "else:\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        props = torch.cuda.get_device_properties(0)\n",
    "        print(f\"Memory: {props.total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "854d0830",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "854d0830",
    "outputId": "0a6d33c8-521e-48fe-955b-460f73b04967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/MyDrive/chart-hero/chart-hero\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# Set up project directory\n",
    "ROOT_DIR = \"/content/drive/MyDrive/chart-hero\"\n",
    "PROJECT_DIR = os.path.join(ROOT_DIR, \"chart-hero\")\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "%cd {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6042b436",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6042b436",
    "outputId": "eac2b073-f8e3-4c57-a06f-01d3736a2fd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD is now at 9e84295 Merge pull request #52 from maple-buice/codex/optimize-cloudconfig-for-t4-high-ram-colab\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "# Clone or update repository\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\".git\"):\n",
    "    !git clone https://github.com/maple-buice/chart-hero.git .\n",
    "else:\n",
    "    !git reset --hard origin/main\n",
    "    !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b06629d",
   "metadata": {
    "id": "5b06629d"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install -q -r requirements.txt torch_xla torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ec6a0",
   "metadata": {
    "id": "b77ec6a0"
   },
   "source": [
    "## 2. Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e39a373",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e39a373",
    "outputId": "c4943d8b-6bf7-4a8e-ceff-e17e0747de65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset dir: /content/drive/MyDrive/chart-hero/datasets/processed_highres\n",
      "DATASET_TAR: /content/drive/MyDrive/chart-hero/datasets/dataset.tar.gz\n",
      "tar exists: True\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.fflags'\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.FinderInfo'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Paths\n",
    "DATASET_DIR = os.path.join(ROOT_DIR, \"datasets\")\n",
    "DATASET_TAR = os.path.join(DATASET_DIR, \"dataset.tar.gz\")\n",
    "PROCESSED_DIR = os.path.join(DATASET_DIR, \"processed_highres\")\n",
    "\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "print(\"Processed dataset dir:\", PROCESSED_DIR)\n",
    "\n",
    "print(\"DATASET_TAR:\", DATASET_TAR)\n",
    "print(\"tar exists:\", os.path.exists(DATASET_TAR))\n",
    "\n",
    "# Extract prebuilt dataset archive if available\n",
    "if os.path.exists(DATASET_TAR) and not os.listdir(PROCESSED_DIR):\n",
    "    !tar -xzf $DATASET_TAR -C $DATASET_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8c41bd",
   "metadata": {
    "id": "cd8c41bd"
   },
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e327f02",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "8e327f02",
    "outputId": "bd6e60f8-3188-4cae-bd05-991800c8750a"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaple-buice\u001b[0m (\u001b[33mmbuice-org\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3: Error while finding module specification for 'chart_hero.model_training.train_transformer' (ModuleNotFoundError: No module named 'chart_hero')\n"
     ]
    }
   ],
   "source": [
    "# Optional: log in to Weights & Biases\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "# Directories for models and logs\n",
    "MODEL_DIR = os.path.join(PROJECT_DIR, \"models\")\n",
    "LOG_DIR = os.path.join(PROJECT_DIR, \"logs\")\n",
    "RUN_TAG = \"colab_highres_run\"\n",
    "\n",
    "!python -m chart_hero.model_training.train_transformer --config cloud --data-dir \"$PROCESSED_DIR\" --model-dir \"$MODEL_DIR\" --log-dir \"$LOG_DIR\" --experiment-tag \"$RUN_TAG\" --use-wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc829f6",
   "metadata": {
    "id": "fdc829f6"
   },
   "source": [
    "## 4. Resume Training (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0ba031",
   "metadata": {
    "id": "de0ba031"
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(MODEL_DIR, RUN_TAG, \"last.ckpt\")\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    !python -m chart_hero.model_training.train_transformer --config cloud --data-dir \"$PROCESSED_DIR\" --model-dir \"$MODEL_DIR\" --log-dir \"$LOG_DIR\" --experiment-tag \"$RUN_TAG\" --resume --use-wandb\n",
    "else:\n",
    "    print(f\"Checkpoint not found: {CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df42a647",
   "metadata": {
    "id": "df42a647"
   },
   "source": [
    "## 5. Model Evaluation and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a38894e",
   "metadata": {
    "id": "5a38894e"
   },
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from chart_hero.model_training.train_transformer import DrumTranscriptionModule\n",
    "from chart_hero.model_training.transformer_config import get_config\n",
    "\n",
    "config = get_config(\"cloud\")\n",
    "best_model_path = os.path.join(MODEL_DIR, RUN_TAG, \"best_model.ckpt\")\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    model = DrumTranscriptionModule.load_from_checkpoint(best_model_path)\n",
    "    model.eval()\n",
    "    print(\"Model loaded successfully!\")\n",
    "    dummy_input = torch.randn(1, 1, 256, 128)\n",
    "    onnx_path = os.path.join(MODEL_DIR, RUN_TAG, \"drum_transformer.onnx\")\n",
    "    torch.onnx.export(\n",
    "        model.model,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=[\"spectrogram\"],\n",
    "        output_names=[\"logits\"],\n",
    "        dynamic_axes={\n",
    "            \"spectrogram\": {0: \"batch_size\", 2: \"time\"},\n",
    "            \"logits\": {0: \"batch_size\"},\n",
    "        },\n",
    "    )\n",
    "    print(f\"Model exported to ONNX: {onnx_path}\")\n",
    "else:\n",
    "    print(f\"Best model not found: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a3dd7",
   "metadata": {
    "id": "a47a3dd7"
   },
   "source": [
    "## 6. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba8bcd",
   "metadata": {
    "id": "39ba8bcd"
   },
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "print(\"Training completed!\")\n",
    "print(f\"Models saved to: {MODEL_DIR}\")\n",
    "print(f\"Logs saved to: {LOG_DIR}\")\n",
    "print(f\"Datasets saved to: {DATASET_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
