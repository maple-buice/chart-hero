{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55d4acd",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/maple-buice/chart-hero/blob/main/colab/transformer_training_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02d463",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dca1e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available accelerator (GPU or TPU)\n",
    "import os, torch\n",
    "if \"COLAB_TPU_ADDR\" in os.environ:\n",
    "    print(\"TPU detected\")\n",
    "else:\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        props = torch.cuda.get_device_properties(0)\n",
    "        print(f\"Memory: {props.total_memory / 1e9:.1f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d0830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# Set up project directory\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/chart-hero\"\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "%cd {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6042b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone or update repository\n",
    "import os\n",
    "if not os.path.exists(\".git\"):\n",
    "    !git clone https://github.com/maple-buice/chart-hero.git .\n",
    "else:\n",
    "    !git pull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b06629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install -q -r requirements.txt torch_xla torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ec6a0",
   "metadata": {},
   "source": [
    "## 2. Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e39a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Paths\n",
    "DATASET_DIR = os.path.join(PROJECT_DIR, \"datasets\")\n",
    "PROCESSED_DIR = os.path.join(DATASET_DIR, \"processed_highres\")\n",
    "CLONEHERO_SONGS = \"/content/drive/MyDrive/CloneHeroSongs\"  # Update to your songs directory\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "print(\"Processed dataset dir:\", PROCESSED_DIR)\n",
    "\n",
    "# Build dataset if directory is empty\n",
    "if not os.listdir(PROCESSED_DIR):\n",
    "    !python -m chart_hero.train.build_dataset --roots \"$CLONEHERO_SONGS\" --out-dir \"$PROCESSED_DIR\" --config cloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8c41bd",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e327f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: log in to Weights & Biases\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# Directories for models and logs\n",
    "MODEL_DIR = os.path.join(PROJECT_DIR, \"models\")\n",
    "LOG_DIR = os.path.join(PROJECT_DIR, \"logs\")\n",
    "RUN_TAG = \"colab_highres_run\"\n",
    "\n",
    "!python -m chart_hero.model_training.train_transformer --config cloud --data-dir \"$PROCESSED_DIR\" --model-dir \"$MODEL_DIR\" --log-dir \"$LOG_DIR\" --experiment-tag \"$RUN_TAG\" --use-wandb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc829f6",
   "metadata": {},
   "source": [
    "## 4. Resume Training (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0ba031",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(MODEL_DIR, RUN_TAG, \"last.ckpt\")\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    !python -m chart_hero.model_training.train_transformer --config cloud --data-dir \"$PROCESSED_DIR\" --model-dir \"$MODEL_DIR\" --log-dir \"$LOG_DIR\" --experiment-tag \"$RUN_TAG\" --resume --use-wandb\n",
    "else:\n",
    "    print(f\"Checkpoint not found: {CHECKPOINT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df42a647",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a38894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "from chart_hero.model_training.train_transformer import DrumTranscriptionModule\n",
    "from chart_hero.model_training.transformer_config import get_config\n",
    "\n",
    "config = get_config(\"cloud\")\n",
    "best_model_path = os.path.join(MODEL_DIR, RUN_TAG, \"best_model.ckpt\")\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    model = DrumTranscriptionModule.load_from_checkpoint(best_model_path)\n",
    "    model.eval()\n",
    "    print(\"Model loaded successfully!\")\n",
    "    dummy_input = torch.randn(1, 1, 256, 128)\n",
    "    onnx_path = os.path.join(MODEL_DIR, RUN_TAG, \"drum_transformer.onnx\")\n",
    "    torch.onnx.export(model.model, dummy_input, onnx_path, export_params=True, opset_version=11, do_constant_folding=True, input_names=[\"spectrogram\"], output_names=[\"logits\"], dynamic_axes={\"spectrogram\": {0: \"batch_size\", 2: \"time\"}, \"logits\": {0: \"batch_size\"}})\n",
    "    print(f\"Model exported to ONNX: {onnx_path}\")\n",
    "else:\n",
    "    print(f\"Best model not found: {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a3dd7",
   "metadata": {},
   "source": [
    "## 6. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba8bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "print(\"Training completed!\")\n",
    "print(f\"Models saved to: {MODEL_DIR}\")\n",
    "print(f\"Logs saved to: {LOG_DIR}\")\n",
    "print(f\"Datasets saved to: {DATASET_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}